{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git add .\n"
      ],
      "metadata": {
        "id": "bkh3OvOuQHiT",
        "outputId": "3db0040d-acee-445d-8b49-1a7c5bdb23e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### 21i1667 , 21i1665 , 21i1662"
      ],
      "metadata": {
        "id": "CksT2KomP6Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "aYpmmfQ-ZbIh",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade langchain openai  -q  #Run To install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "cYfy2IhtvGVv",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbL5zdf9aG8a",
        "outputId": "39caeb89-1725-4484-f139-df21d0c06aaa",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git (to revision v0.6) to /tmp/pip-install-qczg9ijp/detectron2_7e68ef8341c04f9b9848eb1d1fd14be6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-install-qczg9ijp/detectron2_7e68ef8341c04f9b9848eb1d1fd14be6\n",
            "  Running command git checkout -q d1e04565d3bec8719335b88be9e9b961bf3ec464\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit d1e04565d3bec8719335b88be9e9b961bf3ec464\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (11.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (3.8.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.5.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (3.1.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (4.66.6)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.17.1)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (0.1.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.0.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (3.0.2)\n",
            "Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.3.2)\n",
            "Requirement already satisfied: black==21.4b2 in /usr/local/lib/python3.10/dist-packages (from detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (21.4b2)\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (8.1.7)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.4.4)\n",
            "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (0.10.2)\n",
            "Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2024.9.11)\n",
            "Requirement already satisfied: pathspec<1,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (0.12.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (6.0.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (24.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (3.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.68.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2@ git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install unstructured -q\n",
        "!pip install unstructured[local-inference] -q\n",
        "!pip install detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HwalYTVZoRlH",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6346e40b-c08a-4106-e3bf-1f5fa46d9350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install poppler-utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AssnWUVlxtH"
      },
      "source": [
        "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/directory_loader.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3uUDJ179DSH",
        "outputId": "d6adee2a-245e-46ae-e47c-86ab4c75df12",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y tesseract-ocr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwaCosqsogzw"
      },
      "source": [
        "https://python.langchain.com/en/latest/modules/indexes/text_splitters/getting_started.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vrvV0RDWLGyF"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-community -q   #Run TILL HERE Then go down and run the embeddings I have inserted comment there"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## libraries for images and slides\n",
        "\n",
        "!pip install pillow\n",
        "!pip install requests\n",
        "!pip install python-pptx\n",
        "!pip install gensim==3.8.3\n",
        "!pip install keybert\n",
        "!pip install requests Pillow\n",
        "!pip install google_images_download\n",
        "!pip install google-search-results\n",
        "from pptx import Presentation\n",
        "from pptx.util import Pt, Inches\n",
        "from PIL import Image\n",
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "import requests\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "# Initialize KeyBERT\n",
        "from keybert import KeyBERT\n",
        "kw_model = KeyBERT()\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "VTdtstGHCAk5",
        "outputId": "57d4c03c-4e22-4ef0-a3fc-b90a4dee6deb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.10/dist-packages (1.0.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (11.0.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (3.2.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (4.12.2)\n",
            "Collecting gensim==3.8.3\n",
            "  Using cached gensim-3.8.3.tar.gz (23.4 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.10/dist-packages (from gensim==3.8.3) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from gensim==3.8.3) (1.13.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from gensim==3.8.3) (1.16.0)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==3.8.3) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart_open>=1.8.1->gensim==3.8.3) (1.16.0)\n",
            "Building wheels for collected packages: gensim\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for gensim\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for gensim\n",
            "Failed to build gensim\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (gensim)\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: keybert in /usr/local/lib/python3.10/dist-packages (0.8.5)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.26.4)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from keybert) (13.9.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.5.2)\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from keybert) (3.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (4.12.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.46.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.5.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.26.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.32.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.8.30)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: google_images_download in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (from google_images_download) (4.26.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google_images_download) (2.2.3)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium->google_images_download) (0.27.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium->google_images_download) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium->google_images_download) (2024.8.30)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium->google_images_download) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium->google_images_download) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google_images_download) (24.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google_images_download) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google_images_download) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google_images_download) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google_images_download) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google_images_download) (1.2.2)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium->google_images_download) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google_images_download) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->google_images_download) (0.14.0)\n",
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.10/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqwKly8lTqzl",
        "outputId": "52d4a5ec-448f-421d-b42d-069e38b769d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pypdf._cmap:Advanced encoding [] not implemented yet\n",
            "ERROR:pypdf._cmap:Advanced encoding [] not implemented yet\n",
            "ERROR:pypdf._cmap:Advanced encoding [] not implemented yet\n",
            "ERROR:pypdf._cmap:Advanced encoding [] not implemented yet\n",
            "ERROR:pypdf._cmap:Advanced encoding [] not implemented yet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents loaded: 7007\n",
            "Number of document chunks created: 35980\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "directory = '/content/data'\n",
        "\n",
        "def load_docs(directory):\n",
        "    # Create a list to hold all the loaded documents\n",
        "    documents = []\n",
        "\n",
        "    # Iterate over each file in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.pdf'):\n",
        "            # Construct the full file path\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            # Load the PDF file\n",
        "            pdf_loader = PyPDFLoader(file_path)\n",
        "            documents.extend(pdf_loader.load())  # Append the loaded documents\n",
        "\n",
        "    return documents\n",
        "\n",
        "def split_docs(documents, chunk_size=500, chunk_overlap=20):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "    return docs\n",
        "\n",
        "# Load documents from the specified directory\n",
        "documents = load_docs(directory)\n",
        "print(f\"Number of documents loaded: {len(documents)}\")\n",
        "\n",
        "# Split the loaded documents into chunks\n",
        "docs = split_docs(documents)\n",
        "print(f\"Number of document chunks created: {len(docs)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Suppress pypdf error logs if desired\n",
        "logging.getLogger(\"pypdf\").setLevel(logging.WARNING)\n",
        "\n",
        "directory = '/content/data'\n",
        "\n",
        "def load_docs(directory):\n",
        "    documents = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.pdf'):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            try:\n",
        "                pdf_loader = PyMuPDFLoader(file_path)\n",
        "                loaded_docs = pdf_loader.load()\n",
        "                documents.extend(loaded_docs)\n",
        "                print(f\"Loaded {len(loaded_docs)} pages from {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to load {file_path}: {e}\")\n",
        "    return documents\n",
        "\n",
        "def split_docs(documents, chunk_size=500, chunk_overlap=20):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "    return text_splitter.split_documents(documents)\n",
        "\n",
        "# Load documents from the specified directory\n",
        "documents = load_docs(directory)\n",
        "print(f\"Total number of documents loaded: {len(documents)}\")\n",
        "\n",
        "# Split the loaded documents into chunks\n",
        "docs = split_docs(documents)\n",
        "print(f\"Total number of document chunks created: {len(docs)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ78iJ3fWWdV",
        "outputId": "aef38db3-93bc-4ef6-a3c4-3af991c8c705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1270 pages from Book - Tony Gaddis - Starting Out with C++.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 0 of document /content/data/Data Mining Practical Machine Learning Tools and Techniques 3rd Edition-Manteshbbbb.pdf\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 665 pages from Data Mining Practical Machine Learning Tools and Techniques 3rd Edition-Manteshbbbb.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 559 of document /content/data/Database_Systems.pdf\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1029 pages from Database_Systems.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 0 of document /content/data/Data Structures 1.pdf\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 738 pages from Data Structures 1.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 2 of document /content/data/Algo Book.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 12 of document /content/data/Algo Book.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 20 of document /content/data/Algo Book.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 499 of document /content/data/Algo Book.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 787 of document /content/data/Algo Book.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 1161 of document /content/data/Algo Book.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 1250 of document /content/data/Algo Book.pdf\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1313 pages from Algo Book.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 0 of document /content/data/Deep Learning by Ian Goodfellow, Yoshua Bengio, Aaron Courville (z-lib.org).pdf\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 801 pages from Deep Learning by Ian Goodfellow, Yoshua Bengio, Aaron Courville (z-lib.org).pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 1 of document /content/data/eisenstein-natural-language-processing.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 11 of document /content/data/eisenstein-natural-language-processing.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 29 of document /content/data/eisenstein-natural-language-processing.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 85 of document /content/data/eisenstein-natural-language-processing.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 139 of document /content/data/eisenstein-natural-language-processing.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 141 of document /content/data/eisenstein-natural-language-processing.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 161 of document /content/data/eisenstein-natural-language-processing.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 273 of document /content/data/eisenstein-natural-language-processing.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 299 of document /content/data/eisenstein-natural-language-processing.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 301 of document /content/data/eisenstein-natural-language-processing.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 395 of document /content/data/eisenstein-natural-language-processing.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 419 of document /content/data/eisenstein-natural-language-processing.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 491 of document /content/data/eisenstein-natural-language-processing.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 501 of document /content/data/eisenstein-natural-language-processing.pdf\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 587 pages from eisenstein-natural-language-processing.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 40 of document /content/data/Data Mining and Analysis by Zaki.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 224 of document /content/data/Data Mining and Analysis by Zaki.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 338 of document /content/data/Data Mining and Analysis by Zaki.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 340 of document /content/data/Data Mining and Analysis by Zaki.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 473 of document /content/data/Data Mining and Analysis by Zaki.pdf\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/parsers/pdf.py:299: UserWarning: Warning: Empty content on page 591 of document /content/data/Data Mining and Analysis by Zaki.pdf\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 604 pages from Data Mining and Analysis by Zaki.pdf\n",
            "Total number of documents loaded: 7007\n",
            "Total number of document chunks created: 35122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t54HueEUW6-Q",
        "outputId": "1e6a7bb2-c140-4776-8d5c-4cac76f0e258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Document 1:\n",
            "Credits and acknowledgments borrowed from other sources and reproduced, with permission, appear on the \n",
            "Credits page in the endmatter of this textbook.\n",
            "Copyright © 2015, 2012, 2009 Pearson Education, Inc., publishing as Addison-Wesley All rights reserved. \n",
            "Manufactured in the United States of America. This publication is protected by Copyright, and permission \n",
            "should be obtained from the publisher prior to any prohibited reproduction, storage in a retrieval system, or\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Cleaned Document 2:\n",
            "transmission in any form or by any means, electronic, mechanical, photocopying, recording, or likewise. To \n",
            "obtain permission(s) to use material from this work, please submit a written request to Pearson Education, \n",
            "Inc., Permissions Department, One Lake Street, Upper Saddle River, New Jersey 07458 or you may fax your \n",
            "request to 201 236-3290.\n",
            "Many of the designations by manufacturers and sellers to distinguish their products are claimed as trademarks.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Cleaned Document 3:\n",
            "Where those designations appear in this book, and the publisher was aware of a trademark claim, the \n",
            "designations have been printed in initial caps or all caps.\n",
            "Library of Congress Cataloging-in-Publication Data\n",
            "Gaddis, Tony.\n",
            " Starting out with C++ : from control structures through objects/Tony Gaddis.—Eighth edition.\n",
            "  pages cm\n",
            " Includes bibliographical references and index.\n",
            " Online the following appendices are available at www.pearsonhighered.com/gaddis: Appendix D:\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Cleaned Document 4:\n",
            "Introduction to fl  owcharting; Appendix E: Using UML in class design; Appendix F: Namespaces; Appendix G: \n",
            "Writing managed C++ code for the .net framework; Appendix H: Passing command line arguments; Appendix \n",
            "I: Header fi  le and library function reference; Appendix J: Binary numbers and bitwise operations; Appendix K: \n",
            "Multi-source fi  le programs; Appendix L: Stream member functions for formatting; Appendix M: Introduction\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Cleaned Document 5:\n",
            "to Microsoft Visual C++ 2010 express edition; Appendix N: Answers to checkpoints; and Appendix O: \n",
            "Solutions to odd-numbered review questions.\n",
            " ISBN-13: 978-0-13-376939-5\n",
            " ISBN-10: 0-13-376939-9\n",
            " 1. C++ (Computer program language)  I. Title.  II. Title: From control structures through objects.\n",
            "  QA76.73.C153G33 2014b\n",
            "  005.13’3—dc23\n",
            "                                                            2014000213\n",
            "10  9  8  7  6  5  4  3  2  1   Editorial Director: Marcia Horton\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print the first 5 cleaned document chunks\n",
        "for i, doc in enumerate(docs[5:10]):\n",
        "    print(f\"Cleaned Document {i + 1}:\")\n",
        "    print(doc.page_content)\n",
        "    print(\"\\n\" + \"-\" * 80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGCbi4niFSVX",
        "outputId": "fc750340-b477-4957-db26-5aaa170f237e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of cleaned document chunks: 35980\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Cleans a single text string by performing various cleaning steps,\n",
        "    including removing page numbers, headers, and footers.\n",
        "    \"\"\"\n",
        "    # Remove extra whitespaces, tabs, and newlines\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Remove patterns that typically indicate page numbers, e.g., \"Page 1\", \"1 of 10\", etc.\n",
        "    text = re.sub(r'\\bpage\\s*\\d+\\b', '', text, flags=re.IGNORECASE)  # Matches \"Page 1\"\n",
        "    text = re.sub(r'\\b\\d+\\s*(of|/)\\s*\\d+\\b', '', text, flags=re.IGNORECASE)  # Matches \"1 of 10\" or \"1/10\"\n",
        "\n",
        "    # Remove common header/footer indicators (customize this part based on your documents)\n",
        "    text = re.sub(r'(header|footer|chapter\\s*\\d+|section\\s*\\d+)', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove any lines that are too short (likely headers/footers, e.g., under 5 characters)\n",
        "    text = re.sub(r'\\b\\w{1,4}\\b', '', text)\n",
        "\n",
        "    # Remove special characters (except common punctuation marks)\n",
        "    text = re.sub(r'[^\\w\\s.,?!]', '', text)\n",
        "\n",
        "    # Convert to lowercase (optional, depending on use case)\n",
        "    #text = text.lower()\n",
        "\n",
        "    return text\n",
        "\n",
        "def clean_documents(documents):\n",
        "    \"\"\"\n",
        "    Cleans the text for each document in the list by removing headers, footers, and other noise.\n",
        "    \"\"\"\n",
        "    cleaned_docs = []\n",
        "    for doc in documents:\n",
        "        # Clean the content of the document\n",
        "        cleaned_content = clean_text(doc.page_content)\n",
        "        # Update the cleaned content in the document\n",
        "        doc.page_content = cleaned_content\n",
        "        cleaned_docs.append(doc)\n",
        "\n",
        "    return cleaned_docs\n",
        "\n",
        "# Clean the loaded document chunks\n",
        "cleaned_docs = clean_documents(docs)\n",
        "print(f\"Number of cleaned document chunks: {len(cleaned_docs)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PiPwt-FaYwl",
        "outputId": "c59f3051-543d-48c8-ec7d-d99a9d4df569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Document 1:\n",
            "Starting    Eighth .  Gaddis Computer Science  University  Texas  Austin  . Document shared  .docsity.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Cleaned Document 2:\n",
            "Document shared  .docsity.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Cleaned Document 3:\n",
            " EIGHTH EDITION STARTING     Control Structures through Objects Document shared  .docsity.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Cleaned Document 4:\n",
            "  intentionally  blank Document shared  .docsity.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Cleaned Document 5:\n",
            " EIGHTH EDITION STARTING     Control Structures through Objects  Gaddis Haywood Community College Boston Columbus Indianapolis    Francisco Upper Saddle River Amsterdam   Dubai London Madrid Milan Munich Paris Montreal Toronto Delhi Mexico   Paulo Sydney   Seoul Singapore Taipei Tokyo Document shared  .docsity.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print the first 5 cleaned document chunks\n",
        "for i, doc in enumerate(cleaned_docs[:5]):\n",
        "    print(f\"Cleaned Document {i + 1}:\")\n",
        "    print(doc.page_content)\n",
        "    print(\"\\n\" + \"-\" * 80 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "F5GY9voPa0av"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Now run start running from here and go till end\n",
        "\n",
        "\n",
        "\n",
        "# import openai\n",
        "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "# embeddings = OpenAIEmbeddings(model_name=\"ada\")\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s2p3rUwvOvW",
        "outputId": "c7084005-6420-4b88-827e-238837f8f2c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "query_result = embeddings.embed_query(\"Hello world\")\n",
        "len(query_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "LXhIY5SrrRec"
      },
      "outputs": [],
      "source": [
        "!pip install pinecone-client -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vySq5oI5sU5V"
      },
      "source": [
        "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/pinecone.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "hfIpYLV-acks",
        "outputId": "b47116f0-7f46-491e-a18e-46ef7cf33b8f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnauthorizedException",
          "evalue": "(401)\nReason: Unauthorized\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2024-07', 'X-Cloud-Trace-Context': '442f7a837697debe6319446847fb240b', 'Date': 'Mon, 25 Nov 2024 11:21:36 GMT', 'Content-Type': 'text/html', 'Server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: Invalid API Key\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnauthorizedException\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-84c234497613>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Check for existing indexes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mexisting_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindex_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Create the index if it does not exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/control/pinecone.py\u001b[0m in \u001b[0;36mlist_indexes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \"\"\"\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndexList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/shared/api_client.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \"\"\"\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/control/api/manage_indexes_api.py\u001b[0m in \u001b[0;36m__list_indexes\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_check_return_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_check_return_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_host_index\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_host_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         self.list_indexes = _Endpoint(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/shared/api_client.py\u001b[0m in \u001b[0;36mcall_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheader_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         return self.api_client.call_api(\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"endpoint_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"http_method\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/shared/api_client.py\u001b[0m in \u001b[0;36mcall_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \"\"\"\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masync_req\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             return self.__call_api(\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0mresource_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/shared/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPineconeApiException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/shared/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;31m# perform request and return response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             response_data = self.request(\n\u001b[0m\u001b[1;32m    176\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/shared/api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;34m\"\"\"Makes the HTTP request using RESTClient.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             return self.rest_client.GET(\n\u001b[0m\u001b[1;32m    435\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/shared/rest.py\u001b[0m in \u001b[0;36mGET\u001b[0;34m(self, url, headers, query_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mGET\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_preload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         return self.request(\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/shared/rest.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m401\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUnauthorizedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m403\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnauthorizedException\u001b[0m: (401)\nReason: Unauthorized\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2024-07', 'X-Cloud-Trace-Context': '442f7a837697debe6319446847fb240b', 'Date': 'Mon, 25 Nov 2024 11:21:36 GMT', 'Content-Type': 'text/html', 'Server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: Invalid API Key\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "import time\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
        "\n",
        "#074e0d9a-ab5e-48bf-8eae-9effae335521              This is the API to MYDB Insert this\n",
        "\n",
        "# Prompt for Pinecone API key if not set in the environment\n",
        "if not os.getenv(\"PINECONE_API_KEY\"):\n",
        "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
        "\n",
        "# Retrieve the Pinecone API key from environment variables\n",
        "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n",
        "\n",
        "# Define your index name\n",
        "index_name = \"newdata\"  # Change if desired\n",
        "\n",
        "# Check for existing indexes\n",
        "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
        "\n",
        "# Create the index if it does not exist\n",
        "if index_name not in existing_indexes:\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,  # Adjust this to match your embeddings' dimension\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "\n",
        "    # Wait until the index is ready\n",
        "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
        "        print(\"Waiting for the index to be ready...\")\n",
        "        time.sleep(1)\n",
        "\n",
        "# Connect to the index\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Print connection success message\n",
        "print(f\"Successfully connected to the index: {index_name}\")\n",
        "\n",
        "\n",
        "# Now create a Pinecone index for Langchain using the existing index\n",
        "langchain_index = LangchainPinecone.from_existing_index(\n",
        "    index_name=index_name,\n",
        "    embedding=embeddings\n",
        "\n",
        ")\n",
        "\n",
        "# Output to verify the index creation\n",
        "print(f\"Successfully created or connected to the Langchain index: {langchain_index}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5r7YLpbchAD",
        "outputId": "0f6c539f-172e-4fe8-94b9-dbddefc26841"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conservative phase locking, requiresthateverytransaction lockalltheitemsit needsin    1read_lock  read_item  readJock read_item writeJock writeJock  FIGURE18.5Illustrating thedeadlock problem.  partial schedule  .   thatisin  stateof deadlock. Awaitforgraph   partial schedule  . .These protocols   generally   practice, either because  unrealistic assumptionsor\n",
            "schedules thatis,someserializable schedules  beprohibited bytheprotocol.  addition, theuse oflockscancausetwoadditional problems deadlock andstarvation.  discusstheseproblems andtheirsolutions inthenextsection. ..3DealingwithDeadlock  Starvation Deadlock occurswheneachtransaction   setoftwoormoretransactions iswaitingfor someitemthatislockedbysomeothertransaction intheset.Hence,eachtransaction     onawaitingqueue,waitingforoneoftheothertransactions intheset \n",
            "becauseoftheir possibleoverhead. Deadlock detection  timeouts seebelow morepractical.\n",
            "deadlock, sinceT waits  onlyifTS. Thomas WriteRule. Amodification ofthebasicTOalgorithm, knownas Thomas writerule,doesnotenforceconflictserializability butitrejectsfewerwrite operations, bymodifying thechecksforthewrite_itemoperation  follows . Ifread_TS,thenabortandrollbackTandrejecttheoperation. .Ifwrite_TS,thendonotexecutethewriteoperation butcontinue processing. Thisisbecause sometransaction withtimestamp greaterthan\n",
            "Eswaranet . .Bernstein  .,GrayandReuter,andPapadimi trioufocusonconcurrency controlandrecovery. Kumarfocusesonperfor mance  concurrency controlmethods. Locking  discussed    . , andWeinberger ,KedemandSilbershatz ,andKorth.Deadlocks andwaitforgraphswereformalized byHolt,andthewaitwound andwound schemesare presented inRosenkrantz  ..Cautious waitingis discussed  \n",
            "releasethelockonanitem.Asimpleexample isshownin Figure .,wherethetwo transactions andTzaredeadlocked  apartialschedule isonthewaitingqueue ,whichislockedbyT2whileT2isonthewaitingqueueforY,whichislockedby .Meanwhile, neitherTInorTznoranyothertransaction canaccessitemsXandY. Deadlock Prevention Protocols. Oneway  prevent deadlock istouse  deadlock prevention protocol. Onedeadlock prevention protocol, whichis  \n",
            "instead, waitsuntilalltheitems  available forlocking. Conservative 2PLisa deadlock protocol,  weshallsee ..3whenwe discuss thedeadlock problem. However,   difficult touse inpractice because  theneedtopredeclare  setandwrite, whichisnotpossible   situations. Inpractice, themostpopularvariation of2PLisstrict2PL,whichguarantees strict schedules ..Inthisvariation, atransaction  doesnotreleaseany ofits\n",
            "mademanychanges. Another simpleschemetodealwithdeadlock istheuse oftimeouts, Thismethodis practicalbecauseof   overhead andsimplicity. Inthismethod,  atransaction waits foraperiodlongerthanasystemdefined timeout period,thesystem assumes thatthe transaction   deadlocked andabortsitregardless ofwhether adeadlock actually existsornot. Starvation. Another problem thatmayoccurwhenwe uselockingisstarvation, whichoccurswhenatransaction cannotproceed  anindefinite periodoftimewhile\n",
            "Selected BibliographyI995 Nijssen,.,.  Modelling inDataBaseManagement Systems, NorthHolland, . Nijssen,.,.  Architecture andModels  DataBaseManagement Systems, NorthHolland, . Nwosu, ., Berra, ., Thuraisingham, ., . , DesignandImplementation  Multimedia Database Management Systems, KluwerAcademic, . Obermarck, .  Distributed Deadlock Detection Algorithms, ,,  .\n",
            " unlock ifLOCKwriteIocked thenbeginLOCK ..unlocked wakeuponeofthewaitingtransactions, ifany  elseifLOCKlocked thenbegin no_oUeads no_oUeads  ifno_oUeacts thenbeginLOCK unlocked wakeuponeofthewaitingtransactions, ifany   FIGURE18.2Lockingandunlocking operations fortwo write  sharedexclusive locks. . Atransaction  willnotissue awrite_lockoperation  italreadyholdsa\n",
            "itemthatdescribes thestatusoftheitemwithrespectto possible operations thatcan  appliedto .Generally, thereisonelock foreachdataiteminthedatabase. Locks   asameansofsynchronizing theaccess  concurrent transactions tothedatabase items.  ..  discuss thenatureandtypesoflocks. ,.., wepresentprotocols thatuselockingtoguarantee serializability oftransaction schedules. Finally,  ..  discuss  problems associated withtheuse oflocks\n",
            "considered indivisible nointerleaving shouldbeallowedonceoneoftheoperations  starteduntileithertheoperation terminates bygranting thelockorthetransaction  placedonawaitingqueuefortheitem. Whenwe usethesharedexclusive locking scheme, thesystemmustenforcethe following rules .Atransaction Tmustissuetheoperation read_lock  write_lockbefore anyread_itemoperation isperformed . . Atransaction Tmustissuetheoperation write_lockbeforeany write_ operation isperformed .\n",
            "algorithm,  atransaction isunabletoobtaina ,   immediately abortedand  restarted afteracertaintimedelaywithout checking whether adeadlock  actually occurornot.Because thisschemecancausetransactions toabortandrestartneedlessly, thecautious waitingalgorithm wasproposed    reducethenumber  needless abortsrestarts. Suppose thattransaction Tjtries    itemXbutisnotable    becauseX islockedby  othertransaction Tjwithaconflicting .Thecautious\n",
            "Distributed concurrency controltechniques basedonlockinganddistinguished copiesare presented byMenasce .andMinoura andWiederhold .Obermark presents algorithms fordistributed deadlock detection.  survey  recovery techniques indistributed systems  givenbyKohler. discusses atomicactionsondistributed .AbookeditedbyBhargava presents variousapproaches andtechniques forconcurrency  reliability  distributed systems.\n",
            "onallblockedtransactions, sonocyclethatcausesdeadlock canoccur. Deadlock Detection andTimeouts. Asecond practicalapproach  dealingwithdeadlock isdeadlock detection, wherethesystemchecksif astateof deadlock actually exists.Thissolution isattractive  weknowtherewill  little interference amongthetransactions , ifdifferent transactions  rarely access thesame itemsatthesametime.Thiscanhappenifthetransactions areshortandeach\n",
            " orwriteanitemunlessthetransaction thatlastwrotetheitemhascommitted  abortedandrolledback.However, deadlocks canoccurinstricttwophase locking, \n",
            "submitted tothesystem, atimestamp canbethought  asthetransaction starttime.   refer  thetimestamp oftransaction  .Concurrency controltechniques basedontimestamp ordering donotuse locks hence,deadlocks cannotoccur. Timestamps canbegenerated inseveralways.Onepossibility     counterthat isincremented eachtimeitsvalueisassigned  atransaction. Thetransaction timestamps arenumbered ,, ,...inthisscheme. Acomputer counter   finite\n",
            "according tothatorder.Thisrequiresthattheprogrammer orthesystem  aware ofthe chosenorderoftheitems,whichis alsonotpractical inthedatabase context. Anumber ofotherdeadlock prevention schemes havebeenproposed thatmake  decision aboutwhatto dowithatransaction involved  apossible deadlock situation Shouldit beblockedandmadetowaitorshouldit beaborted, orshouldthetransaction preempt andabortanothertransaction? Thesetechniques usetheconcept oftransaction\n",
            "namely,deadlock andstarvation   theseproblems arehandled. ..1Types  Locks  System  Tables Severaltypes  locks    concurrency control.Tointroduce lockingconcepts  ually,  first discuss binarylocks,whichare simple  restrictive    notused  practice. Wethendiscusssharedexclusive locks,whichprovidemoregenerallockingcapa bilitiesandare   practical database lockingschemes.  ..,  describe \n",
            ".Phase LockingTechniques forConcurrency ControlI587 readJock ifLOCKunlocked thenbeginLOCKlocked no_oCreacts  elseifLOCKIocked thenno_oCreacts no_of_reacts  elsebeginwait untilLOCKunlocked  thelocimanagerwakesupthetransaction gotoS  writeJock ifLOCKunlocked thenLOCKwritelocked elsebegin untilLOCKunlocl  thelockmanagerwakesupthetransaction goto8  unlock\n"
          ]
        }
      ],
      "source": [
        "def get_similar_docs(query, k=20, score=True):\n",
        "    if score:\n",
        "        similar_docs = langchain_index.similarity_search_with_score(query, k=k)  # Use langchain_index\n",
        "    else:\n",
        "        similar_docs = langchain_index.similarity_search(query, k=k)  # Use langchain_index\n",
        "    return similar_docs\n",
        "\n",
        "# Example query\n",
        "query = \"How to avoid deadlocks in os?\"\n",
        "similar_docs = get_similar_docs(query)\n",
        "\n",
        "# Output the similar documents\n",
        "for doc in similar_docs:\n",
        "    print(doc[0].page_content)  # This will print the similar documents found\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVOoc9GXHjOG"
      },
      "source": [
        "How is India's economy?\n",
        "\n",
        "and its culture?\n",
        "\n",
        "its relationship with USA?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlkrKhY1PMXm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# ----------------------------------------\n",
        "# Configuration\n",
        "# ----------------------------------------\n",
        "\n",
        "# Set your Hugging Face API key securely\n",
        "# It's recommended to set this as an environment variable for security\n",
        "# For example, in your terminal:\n",
        "# export HUGGINGFACE_API_KEY='your-huggingface-api-key'\n",
        "\n",
        "# Alternatively, you can set it directly in the script (not recommended for production)\n",
        "os.environ[\"HUGGINGFACE_API_KEY\"] = \"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\"  # Replace with your actual API key\n",
        "\n",
        "# Hugging Face model details\n",
        "HUGGINGFACE_API_URL = \"https://api-inference.huggingface.co/models/{model}\"\n",
        "  # You can choose any suitable model\n",
        "# For question-answering tasks, models like \"distilbert-base-uncased-distilled-squad\" can be used\n",
        "# Ensure the chosen model supports the desired task\n",
        "\n",
        "# ----------------------------------------\n",
        "# Initialize LangChain Index\n",
        "# ----------------------------------------\n",
        "\n",
        "# Replace the following with your actual LangChain index initialization\n",
        "# Example using FAISS:\n",
        "# from langchain.vectorstores import FAISS\n",
        "# from langchain.embeddings import HuggingFaceEmbedd1111111111111ings\n",
        "#\n",
        "# embeddings = HuggingFaceEmbeddings()\n",
        "# langchain_index = FAISS.load_local(\"path_to_faiss_index\", embeddings)\n",
        "\n",
        "# For demonstration purposes, we'll assume langchain_index is already initialized.\n",
        "# Make sure to replace the following line with your actual index.\n",
        "  # Replace with your LangChain index initialization\n",
        "\n",
        "# ----------------------------------------\n",
        "# Function to Retrieve Similar Documents\n",
        "# ----------------------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "# Set the Hugging Face API key directly inside the script\n",
        "HUGGINGFACE_API_TOKEN = \"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\"  # Replace with your actual API key\n",
        "\n",
        "# Define the model name\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"  # Replace with your chosen model\n",
        "\n",
        "# Construct the API URL\n",
        "HUGGINGFACE_API_URL = f\"https://api-inference.huggingface.co/models/{model_name}\"\n",
        "\n",
        "# Set up the headers with the authorization token\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {HUGGINGFACE_API_TOKEN}\"\n",
        "}\n",
        "\n",
        "# Example query\n",
        "query = \"How to avoid deadlock in OS?\"\n",
        "\n",
        "# Assuming you have a function `get_similar_docs` defined\n",
        "similar_docs = get_similar_docs(query)\n",
        "\n",
        "# Prepare the context from similar_docs\n",
        "context = \"\\n\\n\".join([doc[0].page_content for doc in similar_docs])\n",
        "\n",
        "\n",
        "prompt = (\n",
        "    f\"Context:\\n{context}\\n\\n\"\n",
        "    f\"Question: {query}\\n\"\n",
        "    f\"Answer: Imagine you are teaching this topic to someone unfamiliar with it. Provide a detailed, easy-to-understand explanation that includes examples, comparisons, and context to help them fully grasp the concept.\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Function to query Hugging Face Inference API\n",
        "def query_huggingface_api(prompt, max_length=25000):\n",
        "    payload = {\n",
        "        \"inputs\": prompt,\n",
        "        \"parameters\": {\n",
        "            \"max_new_tokens\": max_length,\n",
        "            \"temperature\": 0.7,\n",
        "            \"top_p\": 0.9,\n",
        "            \"top_k\": 50,\n",
        "            \"repetition_penalty\": 1.1,\n",
        "            \"do_sample\": True,\n",
        "            \"stop\": [\"<|endoftext|>\"]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    response = requests.post(\n",
        "        HUGGINGFACE_API_URL,\n",
        "        headers=headers,\n",
        "        json=payload\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(response.json())\n",
        "        return response.json()\n",
        "    else:\n",
        "        raise Exception(\n",
        "            f\"Request failed with status code {response.status_code}: {response.text}\"\n",
        "        )\n",
        "\n",
        "# Function to extract answer from API response\n",
        "def extract_answer(api_response):\n",
        "    if isinstance(api_response, list) and len(api_response) > 0:\n",
        "        generated_text = api_response[0].get('generated_text', '')\n",
        "        # Assuming the model appends the answer after \"Answer:\"\n",
        "        answer = generated_text.split(\"Answer:\")[-1].strip() if \"Answer:\" in generated_text else generated_text.strip()\n",
        "        if len(answer) > 25000:\n",
        "            answer = answer[:25000] + \"...\"\n",
        "        return answer\n",
        "    else:\n",
        "        return \"No answer generated.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Generate the answer using Hugging Face Inference API\n",
        "try:\n",
        "    api_response = query_huggingface_api(prompt, max_length=25000)\n",
        "    answer = extract_answer(api_response)\n",
        "    print(\"Answer:\", answer)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", str(e))\n",
        "\n"
      ],
      "metadata": {
        "id": "sOJfoO9mCih4",
        "outputId": "62fe2b51-f4b1-4ad3-e54a-a18b942863c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': \"Context:\\nconservative phase locking, requiresthateverytransaction lockalltheitemsit needsin    1read_lock  read_item  readJock read_item writeJock writeJock  FIGURE18.5Illustrating thedeadlock problem.  partial schedule  .   thatisin  stateof deadlock. Awaitforgraph   partial schedule  . .These protocols   generally   practice, either because  unrealistic assumptionsor\\n\\nschedules thatis,someserializable schedules  beprohibited bytheprotocol.  addition, theuse oflockscancausetwoadditional problems deadlock andstarvation.  discusstheseproblems andtheirsolutions inthenextsection. ..3DealingwithDeadlock  Starvation Deadlock occurswheneachtransaction   setoftwoormoretransactions iswaitingfor someitemthatislockedbysomeothertransaction intheset.Hence,eachtransaction     onawaitingqueue,waitingforoneoftheothertransactions intheset \\n\\nbecauseoftheir possibleoverhead. Deadlock detection  timeouts seebelow morepractical.\\n\\ndeadlock, sinceT waits  onlyifTS. Thomas WriteRule. Amodification ofthebasicTOalgorithm, knownas Thomas writerule,doesnotenforceconflictserializability butitrejectsfewerwrite operations, bymodifying thechecksforthewrite_itemoperation  follows . Ifread_TS,thenabortandrollbackTandrejecttheoperation. .Ifwrite_TS,thendonotexecutethewriteoperation butcontinue processing. Thisisbecause sometransaction withtimestamp greaterthan\\n\\nreleasethelockonanitem.Asimpleexample isshownin Figure .,wherethetwo transactions andTzaredeadlocked  apartialschedule isonthewaitingqueue ,whichislockedbyT2whileT2isonthewaitingqueueforY,whichislockedby .Meanwhile, neitherTInorTznoranyothertransaction canaccessitemsXandY. Deadlock Prevention Protocols. Oneway  prevent deadlock istouse  deadlock prevention protocol. Onedeadlock prevention protocol, whichis  \\n\\nmademanychanges. Another simpleschemetodealwithdeadlock istheuse oftimeouts, Thismethodis practicalbecauseof   overhead andsimplicity. Inthismethod,  atransaction waits foraperiodlongerthanasystemdefined timeout period,thesystem assumes thatthe transaction   deadlocked andabortsitregardless ofwhether adeadlock actually existsornot. Starvation. Another problem thatmayoccurwhenwe uselockingisstarvation, whichoccurswhenatransaction cannotproceed  anindefinite periodoftimewhile\\n\\ninstead, waitsuntilalltheitems  available forlocking. Conservative 2PLisa deadlock protocol,  weshallsee ..3whenwe discuss thedeadlock problem. However,   difficult touse inpractice because  theneedtopredeclare  setandwrite, whichisnotpossible   situations. Inpractice, themostpopularvariation of2PLisstrict2PL,whichguarantees strict schedules ..Inthisvariation, atransaction  doesnotreleaseany ofits\\n\\nEswaranet . .Bernstein  .,GrayandReuter,andPapadimi trioufocusonconcurrency controlandrecovery. Kumarfocusesonperfor mance  concurrency controlmethods. Locking  discussed    . , andWeinberger ,KedemandSilbershatz ,andKorth.Deadlocks andwaitforgraphswereformalized byHolt,andthewaitwound andwound schemesare presented inRosenkrantz  ..Cautious waitingis discussed  \\n\\n unlock ifLOCKwriteIocked thenbeginLOCK ..unlocked wakeuponeofthewaitingtransactions, ifany  elseifLOCKlocked thenbegin no_oUeads no_oUeads  ifno_oUeacts thenbeginLOCK unlocked wakeuponeofthewaitingtransactions, ifany   FIGURE18.2Lockingandunlocking operations fortwo write  sharedexclusive locks. . Atransaction  willnotissue awrite_lockoperation  italreadyholdsa\\n\\nconsidered indivisible nointerleaving shouldbeallowedonceoneoftheoperations  starteduntileithertheoperation terminates bygranting thelockorthetransaction  placedonawaitingqueuefortheitem. Whenwe usethesharedexclusive locking scheme, thesystemmustenforcethe following rules .Atransaction Tmustissuetheoperation read_lock  write_lockbefore anyread_itemoperation isperformed . . Atransaction Tmustissuetheoperation write_lockbeforeany write_ operation isperformed .\\n\\nalgorithm,  atransaction isunabletoobtaina ,   immediately abortedand  restarted afteracertaintimedelaywithout checking whether adeadlock  actually occurornot.Because thisschemecancausetransactions toabortandrestartneedlessly, thecautious waitingalgorithm wasproposed    reducethenumber  needless abortsrestarts. Suppose thattransaction Tjtries    itemXbutisnotable    becauseX islockedby  othertransaction Tjwithaconflicting .Thecautious\\n\\nSelected BibliographyI995 Nijssen,.,.  Modelling inDataBaseManagement Systems, NorthHolland, . Nijssen,.,.  Architecture andModels  DataBaseManagement Systems, NorthHolland, . Nwosu, ., Berra, ., Thuraisingham, ., . , DesignandImplementation  Multimedia Database Management Systems, KluwerAcademic, . Obermarck, .  Distributed Deadlock Detection Algorithms, ,,  .\\n\\nitemthatdescribes thestatusoftheitemwithrespectto possible operations thatcan  appliedto .Generally, thereisonelock foreachdataiteminthedatabase. Locks   asameansofsynchronizing theaccess  concurrent transactions tothedatabase items.  ..  discuss thenatureandtypesoflocks. ,.., wepresentprotocols thatuselockingtoguarantee serializability oftransaction schedules. Finally,  ..  discuss  problems associated withtheuse oflocks\\n\\n orwriteanitemunlessthetransaction thatlastwrotetheitemhascommitted  abortedandrolledback.However, deadlocks canoccurinstricttwophase locking, \\n\\n.Phase LockingTechniques forConcurrency ControlI587 readJock ifLOCKunlocked thenbeginLOCKlocked no_oCreacts  elseifLOCKIocked thenno_oCreacts no_of_reacts  elsebeginwait untilLOCKunlocked  thelocimanagerwakesupthetransaction gotoS  writeJock ifLOCKunlocked thenLOCKwritelocked elsebegin untilLOCKunlocl  thelockmanagerwakesupthetransaction goto8  unlock\\n\\nonallblockedtransactions, sonocyclethatcausesdeadlock canoccur. Deadlock Detection andTimeouts. Asecond practicalapproach  dealingwithdeadlock isdeadlock detection, wherethesystemchecksif astateof deadlock actually exists.Thissolution isattractive  weknowtherewill  little interference amongthetransactions , ifdifferent transactions  rarely access thesame itemsatthesametime.Thiscanhappenifthetransactions areshortandeach\\n\\nDistributed concurrency controltechniques basedonlockinganddistinguished copiesare presented byMenasce .andMinoura andWiederhold .Obermark presents algorithms fordistributed deadlock detection.  survey  recovery techniques indistributed systems  givenbyKohler. discusses atomicactionsondistributed .AbookeditedbyBhargava presents variousapproaches andtechniques forconcurrency  reliability  distributed systems.\\n\\nlock_item andunlock_itern operations intransaction ,     holdthe .    removed   modify thelockjtemi operation  Figure .  thatifthe itemiscurrently lockedbythe requesting transaction, thelock isgranted.\\n\\nsubmitted tothesystem, atimestamp canbethought  asthetransaction starttime.   refer  thetimestamp oftransaction  .Concurrency controltechniques basedontimestamp ordering donotuse locks hence,deadlocks cannotoccur. Timestamps canbegenerated inseveralways.Onepossibility     counterthat isincremented eachtimeitsvalueisassigned  atransaction. Thetransaction timestamps arenumbered ,, ,...inthisscheme. Acomputer counter   finite\\n\\naccording tothatorder.Thisrequiresthattheprogrammer orthesystem  aware ofthe chosenorderoftheitems,whichis alsonotpractical inthedatabase context. Anumber ofotherdeadlock prevention schemes havebeenproposed thatmake  decision aboutwhatto dowithatransaction involved  apossible deadlock situation Shouldit beblockedandmadetowaitorshouldit beaborted, orshouldthetransaction preempt andabortanothertransaction? Thesetechniques usetheconcept oftransaction\\n\\nQuestion: How to avoid deadlock in OS?\\nAnswer: Imagine you are teaching this topic to someone unfamiliar with it. Provide a detailed, easy-to-understand explanation that includes examples, comparisons, and context to help them fully grasp the concept.\\n\\nIn operating systems (OS), deadlock can occur when multiple processes are competing for resources, each holding one or more resources and waiting for another resource held by another process. This leads to a situation where no progress can be made, as each process is waiting for the resource being held by another.\\n\\nTo avoid deadlock, there are two primary approaches: deadlock prevention and deadlock detection.\\n\\nDeadlock Prevention:\\nThis approach aims to design the system such that deadlock cannot occur. It can be achieved by imposing certain restrictions on resource allocation and waiting. For example, the banker's algorithm ensures that resources are always allocated in a safe sequence, meaning that once a process has been granted all the resources it requests, it can complete without needing any additional resources.\\n\\nAnother technique is the ownership matrix, where each process is assigned a matrix that records the resources it currently holds and the resources it still needs. The system checks this matrix before granting new resources to ensure that it won't lead to a deadlock.\\n\\nDeadlock Detection:\\nIf deadlock prevention isn't feasible, deadlock detection can be used. In this approach, the system periodically checks for the existence of deadlock. If a deadlock is detected, one of the processes involved in the deadlock is selected and its resources are forcibly taken away, allowing progress to continue.\\n\\nOne common method for detecting deadlock is the wait-for graph. Each node in the graph represents a process, and edges indicate that one process is waiting for a resource held by another. If a cycle exists in this graph, it indicates a potential deadlock, and the system can take appropriate action.\\n\\nIn summary, deadlock in operating systems can be avoided by either designing the system to prevent deadlock from occurring or by periodically checking for deadlock and taking corrective action when it is detected. The choice between these approaches depends on factors such as the nature of the processes, the resources they require, and the performance characteristics of the system.\"}]\n",
            "Answer: Imagine you are teaching this topic to someone unfamiliar with it. Provide a detailed, easy-to-understand explanation that includes examples, comparisons, and context to help them fully grasp the concept.\n",
            "\n",
            "In operating systems (OS), deadlock can occur when multiple processes are competing for resources, each holding one or more resources and waiting for another resource held by another process. This leads to a situation where no progress can be made, as each process is waiting for the resource being held by another.\n",
            "\n",
            "To avoid deadlock, there are two primary approaches: deadlock prevention and deadlock detection.\n",
            "\n",
            "Deadlock Prevention:\n",
            "This approach aims to design the system such that deadlock cannot occur. It can be achieved by imposing certain restrictions on resource allocation and waiting. For example, the banker's algorithm ensures that resources are always allocated in a safe sequence, meaning that once a process has been granted all the resources it requests, it can complete without needing any additional resources.\n",
            "\n",
            "Another technique is the ownership matrix, where each process is assigned a matrix that records the resources it currently holds and the resources it still needs. The system checks this matrix before granting new resources to ensure that it won't lead to a deadlock.\n",
            "\n",
            "Deadlock Detection:\n",
            "If deadlock prevention isn't feasible, deadlock detection can be used. In this approach, the system periodically checks for the existence of deadlock. If a deadlock is detected, one of the processes involved in the deadlock is selected and its resources are forcibly taken away, allowing progress to continue.\n",
            "\n",
            "One common method for detecting deadlock is the wait-for graph. Each node in the graph represents a process, and edges indicate that one process is waiting for a resource held by another. If a cycle exists in this graph, it indicates a potential deadlock, and the system can take appropriate action.\n",
            "\n",
            "In summary, deadlock in operating systems can be avoided by either designing the system to prevent deadlock from occurring or by periodically checking for deadlock and taking corrective action when it is detected. The choice between these approaches depends on factors such as the nature of the processes, the resources they require, and the performance characteristics of the system.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SgZMRwjHD3Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slides and Images"
      ],
      "metadata": {
        "id": "540llDwAD4XW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to scrape images from GeeksforGeeks using SerpApi\n",
        "def scrape_images(keyword, num_images=2):  # Limit to 1 image\n",
        "    api_key = \"df7729cfcc6f85cfea8e18cb9f13ce5180a3ea6e1c22e2e5f3de3ea16bd6e40b\"  # Replace with your actual API key\n",
        "\n",
        "    params = {\n",
        "        \"engine\": \"google_images\",\n",
        "        \"q\": keyword,\n",
        "        \"google_domain\": \"google.com\",\n",
        "        \"gl\": \"us\",\n",
        "        \"hl\": \"en\",\n",
        "        \"api_key\": api_key,\n",
        "    }\n",
        "\n",
        "    response = requests.get(\"https://serpapi.com/search.json\", params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        images = []\n",
        "\n",
        "        if \"images_results\" in data:\n",
        "            for image in data[\"images_results\"]:\n",
        "                if 'geeksforgeeks' in image.get('source', '').lower():\n",
        "                    images.append(image[\"original\"])\n",
        "                    if len(images) >= num_images:  # Limit to the desired number of images\n",
        "                        break\n",
        "            return images\n",
        "\n",
        "        return []\n",
        "    else:\n",
        "        print(f\"Failed to retrieve images. Status code: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "def generate_slide_title(text):\n",
        "    # Extract keywords or create a brief title from the text\n",
        "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 1), top_n=5)\n",
        "    key_words = [keyword[0] for keyword in keywords]\n",
        "\n",
        "    return \" \".join(key_words[:2]).title()  # Use top 2 keywords as the title\n",
        "\n",
        "def generate_bullet_points(text):\n",
        "    # Split text into sentences and return as bullet points\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    bullets = [sentence for sentence in sentences if len(sentence) > 20]\n",
        "    return bullets\n",
        "\n",
        "import random\n",
        "\n",
        "def create_ppt_from_template(raw_text, templates, main_topic):\n",
        "    # Randomly select a template from the list of templates\n",
        "    selected_template = random.choice(templates)\n",
        "\n",
        "    # Load the selected template\n",
        "    prs = Presentation(selected_template)\n",
        "\n",
        "    # Add the main topic to the first slide's title and adjust font size\n",
        "    if prs.slides:\n",
        "        slide = prs.slides[0]\n",
        "        title = slide.shapes.title\n",
        "        title.text = main_topic\n",
        "        title.text_frame.paragraphs[0].font.size = Pt(40)  # Adjust font size as needed\n",
        "\n",
        "    # Split raw text into paragraphs for better segmentation\n",
        "    sections = raw_text.split(\"\\n\\n\")  # Paragraphs separated by blank lines\n",
        "    slide_titles = []  # Keep track of all generated titles\n",
        "\n",
        "    for section in sections:\n",
        "        if not section.strip():  # Skip empty sections\n",
        "            continue\n",
        "\n",
        "        # Generate slide title and split text into smaller chunks\n",
        "        slide_title = generate_slide_title(section)\n",
        "        slide_titles.append(slide_title)  # Track all slide titles\n",
        "        bullets = nltk.sent_tokenize(section)\n",
        "\n",
        "        max_lines = 8  # Max lines per slide to prevent overflow\n",
        "        content_chunks = [bullets[i:i + max_lines] for i in range(0, len(bullets), max_lines)]\n",
        "\n",
        "        for idx, chunk in enumerate(content_chunks):\n",
        "            # Create a slide with a layout from the selected template\n",
        "            slide_layout = prs.slide_layouts[1]  # Use the template's title and content layout\n",
        "            slide = prs.slides.add_slide(slide_layout)\n",
        "\n",
        "            title = slide.shapes.title\n",
        "            title.text = f\"{slide_title} (Part {idx + 1})\" if len(content_chunks) > 1 else slide_title\n",
        "            title.text_frame.paragraphs[0].font.size = Pt(36)  # Adjust font size as needed\n",
        "\n",
        "            # Add the chunk of text to the slide\n",
        "            textbox = slide.shapes.placeholders[1].text_frame\n",
        "            textbox.clear()  # Clear placeholder text\n",
        "            for bullet in chunk:\n",
        "                p = textbox.add_paragraph()\n",
        "                p.text = bullet\n",
        "                p.font.size = Pt(24)  # Adjust font size for readability\n",
        "\n",
        "    # Randomly select 3 or 4 headings for fetching images\n",
        "    titles_for_images = random.sample(slide_titles, min(len(slide_titles), 4))\n",
        "    title_to_image = {}  # Track fetched images for unique titles\n",
        "\n",
        "    for slide_title in titles_for_images:\n",
        "        images = scrape_images(slide_title, num_images=1)  # Fetch 1 image for the slide title\n",
        "        if images:\n",
        "            title_to_image[slide_title] = images[0]\n",
        "            img_url = images[0]\n",
        "\n",
        "            try:\n",
        "                response = requests.get(img_url)\n",
        "                response.raise_for_status()  # Check for HTTP errors\n",
        "\n",
        "                # Load the image into memory\n",
        "                img = Image.open(BytesIO(response.content))\n",
        "\n",
        "                # Resize the image to fit within slide dimensions\n",
        "                slide_width = Inches(10)  # Typical slide width\n",
        "                slide_height = Inches(7.5)  # Typical slide height\n",
        "                img_width, img_height = img.size\n",
        "\n",
        "                # Maintain aspect ratio while resizing\n",
        "                aspect_ratio = min(slide_width / img_width, slide_height / img_height)\n",
        "                new_width = int(img_width * aspect_ratio)\n",
        "                new_height = int(img_height * aspect_ratio)\n",
        "\n",
        "                image_stream = BytesIO()\n",
        "                img = img.resize((new_width, new_height), Image.ANTIALIAS)\n",
        "                img.save(image_stream, format=\"jpeg\")\n",
        "                image_stream.seek(0)\n",
        "\n",
        "                # Create a new slide for the image\n",
        "                img_slide_layout = prs.slide_layouts[6]  # Use a blank slide layout\n",
        "                img_slide = prs.slides.add_slide(img_slide_layout)\n",
        "\n",
        "                # Center the image on the slide\n",
        "                image_left = (slide_width - Inches(new_width / 72)) / 2  # Convert px to inches\n",
        "                image_top = (slide_height - Inches(new_height / 72)) / 2\n",
        "                img_slide.shapes.add_picture(image_stream, image_left, image_top)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading or resizing image for '{slide_title}': {e}\")\n",
        "\n",
        "    # Save the presentation with the template styles\n",
        "    prs.save(f\"/content/generated_slides/{main_topic}.pptx\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "templates = [\n",
        "    '/content/templates/template.pptx',\n",
        "    '/content/templates/template1.pptx',\n",
        "    '/content/templates/template2.pptx',\n",
        "    '/content/templates/template3.pptx'\n",
        "]  # List of template file paths\n",
        "\n",
        "raw_text = answer\n",
        "main_topic = query.upper()\n",
        "\n",
        "# Create a presentation using one random template\n",
        "create_ppt_from_template(raw_text, templates, main_topic)\n"
      ],
      "metadata": {
        "id": "XXQttYtmD3BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6tr6WQgoD75H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "010QWwwWD708"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_quiz_with_difficulty(answer_text):\n",
        "    \"\"\"\n",
        "    Generate quiz questions (MCQs, short answers, fill-in-the-blanks) with difficulty levels.\n",
        "\n",
        "    Parameters:\n",
        "        answer_text (str): The input text to generate questions from.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing generated questions and their answers, categorized by difficulty.\n",
        "    \"\"\"\n",
        "    quiz = {\"Easy\": [], \"Medium\": [], \"Hard\": []}\n",
        "    lines = [line.strip() for line in answer_text.split(\".\") if len(line.strip()) > 10]\n",
        "\n",
        "    for line in lines:\n",
        "        # Generate a fill-in-the-blank question for the \"Easy\" category\n",
        "        if \" \" in line:\n",
        "            blank_line = line.replace(line.split(\" \")[-1], \"_____\")\n",
        "            quiz[\"Easy\"].append({\"type\": \"Fill-in-the-Blank\", \"question\": blank_line, \"answer\": line.split(\" \")[-1]})\n",
        "\n",
        "        # Medium difficulty: Short-answer question\n",
        "        short_answer_prompt = (\n",
        "            f\"Generate a short-answer question based on this sentence:\\n\"\n",
        "            f\"Sentence: \\\"{line}\\\"\\n\"\n",
        "            f\"Question: \"\n",
        "        )\n",
        "        try:\n",
        "            short_answer = query_huggingface_api(short_answer_prompt, max_length=100)[\"generated_text\"]\n",
        "            quiz[\"Medium\"].append({\"type\": \"Short Answer\", \"question\": short_answer, \"answer\": line})\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to generate short answer: {e}\")\n",
        "\n",
        "        # Hard difficulty: MCQ\n",
        "        mcq_prompt = (\n",
        "            f\"Generate a challenging multiple-choice question based on this sentence:\\n\"\n",
        "            f\"Sentence: \\\"{line}\\\"\\n\"\n",
        "            f\"Question with Options: \"\n",
        "        )\n",
        "        try:\n",
        "            mcq_question = query_huggingface_api(mcq_prompt, max_length=150)[\"generated_text\"]\n",
        "            quiz[\"Hard\"].append({\"type\": \"MCQ\", \"question\": mcq_question, \"answer\": \"(c)\"})  # Assume correct option is c\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to generate MCQ: {e}\")\n",
        "\n",
        "    return quiz\n"
      ],
      "metadata": {
        "id": "BtRV8VeiCkeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiz = generate_quiz_with_difficulty(answer)\n",
        "\n",
        "# Print the generated quiz\n",
        "import pprint\n",
        "pprint.pprint(quiz)"
      ],
      "metadata": {
        "id": "07HrPkf47-Rx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a69220f-453f-4cbb-82dc-6ecc054ee493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'Generate a short-answer question based on this sentence:\\nSentence: \"Imagine you are teaching this topic to someone unfamiliar with it\"\\nQuestion: 1. What strategy would you use when teaching a new topic to someone who is not familiar with it?'}]\n",
            "Failed to generate short answer: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a challenging multiple-choice question based on this sentence:\\nSentence: \"Imagine you are teaching this topic to someone unfamiliar with it\"\\nQuestion with Options: 1. Who is the student in this scenario?\\n   a) A teacher\\n   b) The author of the sentence\\n   c) An individual learning about the topic for the first time\\n   d) A person who has already mastered the topic\\n\\nCorrect Answer: c) An individual learning about the topic for the first time'}]\n",
            "Failed to generate MCQ: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a short-answer question based on this sentence:\\nSentence: \"Provide a detailed, easy-to-understand explanation that includes examples, comparisons, and context to help them fully grasp the concept\"\\nQuestion: 1. Write a concise question that asks for a detailed, easy-to-understand explanation of a complex topic, including examples, comparisons, and context to help the reader fully grasp the concept.\\n\\nExample: What is quantum computing, and how does it differ from traditional computing? Provide examples and comparisons to help us understand its potential impact and advantages.'}]\n",
            "Failed to generate short answer: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a challenging multiple-choice question based on this sentence:\\nSentence: \"Provide a detailed, easy-to-understand explanation that includes examples, comparisons, and context to help them fully grasp the concept\"\\nQuestion with Options:  Which of the following best describes the instruction given in the sentence?\\nA) Write a brief summary without examples or comparisons.\\nB) Create a complex equation with difficult terms.\\nC) Provide a detailed, easy-to-understand explanation that includes examples, comparisons, and context to help them fully grasp the concept.\\nD) Write an abstract interpretation of the concept without practical application.'}]\n",
            "Failed to generate MCQ: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a short-answer question based on this sentence:\\nSentence: \"In operating systems (OS), deadlock can occur when multiple processes are competing for resources, each holding one or more resources and waiting for another resource held by another process\"\\nQuestion:  What is a deadlock in the context of operating systems?'}]\n",
            "Failed to generate short answer: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a challenging multiple-choice question based on this sentence:\\nSentence: \"In operating systems (OS), deadlock can occur when multiple processes are competing for resources, each holding one or more resources and waiting for another resource held by another process\"\\nQuestion with Options:  Which of the following best describes a situation that is most likely to lead to a deadlock in an operating system?\\nA) A single process holding a resource while it waits for no additional resources.\\nB) Multiple processes each holding a different resource but not waiting for any other process\\'s resources.\\nC) Two or more processes each holding one or more resources and waiting for a resource held by another process.\\nD) A single process holding a resource and waiting for another process to finish using its resources.'}]\n",
            "Failed to generate MCQ: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a short-answer question based on this sentence:\\nSentence: \"This leads to a situation where no progress can be made, as each process is waiting for the resource being held by another\"\\nQuestion: 1. In what scenario does each process wait for a resource held by another, resulting in no progress?'}]\n",
            "Failed to generate short answer: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a challenging multiple-choice question based on this sentence:\\nSentence: \"This leads to a situation where no progress can be made, as each process is waiting for the resource being held by another\"\\nQuestion with Options: 1. Which of the following best describes the given scenario?\\na) Resource starvation occurs when one process holds all resources and denies other processes access to them\\nb) Deadlock results from a situation in which two or more processes are unable to proceed because each is waiting for the other to release a resource\\nc) Starvation refers to the case where one process runs infinitely, preventing others from getting CPU time\\nd) Race condition happens when multiple processes try to access shared resources simultaneously without proper synchronization\\nCorrect Answer: b) Deadlock results from a situation in which two or more processes are unable to proceed because each is waiting for the other to release a resource'}]\n",
            "Failed to generate MCQ: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a short-answer question based on this sentence:\\nSentence: \"To avoid deadlock, there are two primary approaches: deadlock prevention and deadlock detection\"\\nQuestion: 1. What are the two primary approaches to avoiding deadlock in a system?\\n\\nAnswer: Deadlock prevention and deadlock detection.'}]\n",
            "Failed to generate short answer: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a challenging multiple-choice question based on this sentence:\\nSentence: \"To avoid deadlock, there are two primary approaches: deadlock prevention and deadlock detection\"\\nQuestion with Options:  Which of the following is NOT a method to handle deadlock in a system?\\nA) Deadlock Prevention\\nB) Deadlock Detection\\nC) Deadlock Recovery\\nD) Deadlock Avoidance\\nAnswer: C) Deadlock Recovery (Deadlock recovery handles the deadlock once it has occurred, while prevention and detection are strategies to prevent or detect deadlock before it occurs.)'}]\n",
            "Failed to generate MCQ: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a short-answer question based on this sentence:\\nSentence: \"Deadlock Prevention:\\nThis approach aims to design the system such that deadlock cannot occur\"\\nQuestion: 1. What is the objective of Deadlock Prevention approach in designing a system? (2 marks)'}]\n",
            "Failed to generate short answer: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a challenging multiple-choice question based on this sentence:\\nSentence: \"Deadlock Prevention:\\nThis approach aims to design the system such that deadlock cannot occur\"\\nQuestion with Options: 1. What is the main objective of Deadlock Prevention Approach?\\nA) To resolve deadlocks after they occur\\nB) To allow deadlocks to happen intentionally\\nC) To ensure that deadlock does not occur in the system\\nD) To improve the performance of the system by causing deadlocks\\nCorrect Answer: C) To ensure that deadlock does not occur in the system'}]\n",
            "Failed to generate MCQ: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a short-answer question based on this sentence:\\nSentence: \"It can be achieved by imposing certain restrictions on resource allocation and waiting\"\\nQuestion:  \"How might one achieve something through the imposition of restrictions on resource allocation and waiting?\"'}]\n",
            "Failed to generate short answer: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a challenging multiple-choice question based on this sentence:\\nSentence: \"It can be achieved by imposing certain restrictions on resource allocation and waiting\"\\nQuestion with Options: 1. What is the subject of this sentence?\\na) Certain restrictions\\nb) Resource allocation and waiting\\nc) Imposing\\nd) It (can be achieved)\\n2. Which of the following best describes the action in this sentence?\\na) Allocating resources\\nb) Waiting\\nc) Restricting resource allocation\\nd) Achieving\\n3. If the subject were to perform an action, what would it be according to this sentence?\\na) Waiting\\nb) Imposing restrictions\\nc) Allocating resources\\nd) Achieving\\n4. What does the subject do to achieve something in this sentence?\\na) Allocate resources\\nb) Impose restrictions on'}]\n",
            "Failed to generate MCQ: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a short-answer question based on this sentence:\\nSentence: \"For example, the banker\\'s algorithm ensures that resources are always allocated in a safe sequence, meaning that once a process has been granted all the resources it requests, it can complete without needing any additional resources\"\\nQuestion:  What is the purpose of the banker\\'s algorithm in resource allocation, and what does \"safe sequence\" mean in this context?'}]\n",
            "Failed to generate short answer: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a challenging multiple-choice question based on this sentence:\\nSentence: \"For example, the banker\\'s algorithm ensures that resources are always allocated in a safe sequence, meaning that once a process has been granted all the resources it requests, it can complete without needing any additional resources\"\\nQuestion with Options: 1. Which of the following is not a characteristic of the banker\\'s algorithm?\\n   A) It ensures resources are always allocated in a safe sequence\\n   B) Once a process has been granted all the resources it requests, it can complete without needing any additional resources\\n   C) It ensures no deadlock occurs\\n   D) It guarantees fairness among processes\\n   E) It allows processes to wait for resources they have already been granted\\nAnswer: E) It allows processes to wait for resources they have already been granted'}]\n",
            "Failed to generate MCQ: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a short-answer question based on this sentence:\\nSentence: \"Another technique is the ownership matrix, where each process is assigned a matrix that records the resources it currently holds and the resources it still needs\"\\nQuestion:  What is an \"ownership matrix\", and what does it record for each process?'}]\n",
            "Failed to generate short answer: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a challenging multiple-choice question based on this sentence:\\nSentence: \"Another technique is the ownership matrix, where each process is assigned a matrix that records the resources it currently holds and the resources it still needs\"\\nQuestion with Options:  Which of the following best describes the purpose of an \"ownership matrix\" in the given context?\\nA) A system to track the progress of processes based on their current resources and unmet requirements.\\nB) A method for assigning resources to processes randomly.\\nC) A tool used to manage the scheduling of processes based on their resource demands.\\nD) A database containing information about the relationships between processes and resources.\\nE) A mechanism for ensuring that no two processes hold the same resource at any given time.'}]\n",
            "Failed to generate MCQ: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a short-answer question based on this sentence:\\nSentence: \"The system checks this matrix before granting new resources to ensure that it won\\'t lead to a deadlock\"\\nQuestion: 1. What does the system check in the given context?\\n          2. What is the purpose of checking the mentioned matrix before granting new resources?\\n          3. What could potentially happen if the system doesn\\'t check the matrix before granting new resources?'}]\n",
            "Failed to generate short answer: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a challenging multiple-choice question based on this sentence:\\nSentence: \"The system checks this matrix before granting new resources to ensure that it won\\'t lead to a deadlock\"\\nQuestion with Options: 1. What does the system check in the given sentence?\\na) A list of tasks\\nb) A network topology\\nc) A matrix of available resources\\nd) A graph of resource allocation\\nAnswer: c) A matrix of available resources'}]\n",
            "Failed to generate MCQ: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a short-answer question based on this sentence:\\nSentence: \"Deadlock Detection:\\nIf deadlock prevention isn\\'t feasible, deadlock detection can be used\"\\nQuestion: 1. What is the role of deadlock detection in case deadlock prevention is not feasible?'}]\n",
            "Failed to generate short answer: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a challenging multiple-choice question based on this sentence:\\nSentence: \"Deadlock Detection:\\nIf deadlock prevention isn\\'t feasible, deadlock detection can be used\"\\nQuestion with Options: 1. Which statement is true about Deadlock Detection?\\n   a) It ensures the system will never experience a deadlock\\n   b) It only works when deadlock prevention methods fail\\n   c) It is always feasible to implement in a system\\n   d) It requires more resources than deadlock prevention methods\\n   Correct Answer: b) It only works when deadlock prevention methods fail'}]\n",
            "Failed to generate MCQ: list indices must be integers or slices, not str\n",
            "[{'generated_text': 'Generate a short-answer question based on this sentence:\\nSentence: \"In this approach, the system periodically checks for the existence of deadlock\"\\nQuestion:  What is the action performed in the given approach to avoid deadlock situations?'}]\n",
            "Failed to generate short answer: list indices must be integers or slices, not str\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-ecffaf3b5f3b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquiz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_quiz_with_difficulty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Print the generated quiz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquiz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-b38e8362769d>\u001b[0m in \u001b[0;36mgenerate_quiz_with_difficulty\u001b[0;34m(answer_text)\u001b[0m\n\u001b[1;32m     37\u001b[0m         )\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mmcq_question\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_huggingface_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcq_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generated_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mquiz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Hard\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"MCQ\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmcq_question\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"answer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"(c)\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assume correct option is c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-6d93d4261033>\u001b[0m in \u001b[0;36mquery_huggingface_api\u001b[0;34m(prompt, max_length)\u001b[0m\n\u001b[1;32m     49\u001b[0m     }\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     response = requests.post(\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mHUGGINGFACE_API_URL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;31m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLSocket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mtls_in_tls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             sock = connection.create_connection(\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OfoSSWYyvYhE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}